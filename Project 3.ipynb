{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "Your local instructor will evaluate your project (for the most part) using the following criteria.  You should make sure that you consider and/or follow most if not all of the considerations/recommendations outlined below **while** working through your project.\n",
    "\n",
    "For Project 3 the evaluation categories are as follows:<br>\n",
    "**The Data Science Process**\n",
    "- Problem Statement\n",
    "- Data Collection\n",
    "- Data Cleaning & EDA\n",
    "- Preprocessing & Modeling\n",
    "- Evaluation and Conceptual Understanding\n",
    "- Conclusion and Recommendations\n",
    "\n",
    "**Organization and Professionalism**\n",
    "- Organization\n",
    "- Visualizations\n",
    "- Python Syntax and Control Flow\n",
    "- Presentation\n",
    "\n",
    "**Scores will be out of 30 points based on the 10 categories in the rubric.** <br>\n",
    "*3 points per section*<br>\n",
    "\n",
    "| Score | Interpretation |\n",
    "| --- | --- |\n",
    "| **0** | *Project fails to meet the minimum requirements for this item.* |\n",
    "| **1** | *Project meets the minimum requirements for this item, but falls significantly short of portfolio-ready expectations.* |\n",
    "| **2** | *Project exceeds the minimum requirements for this item, but falls short of portfolio-ready expectations.* |\n",
    "| **3** | *Project meets or exceeds portfolio-ready expectations; demonstrates a thorough understanding of every outlined consideration.* |\n",
    "\n",
    "\n",
    "### The Data Science Process\n",
    "\n",
    "**Problem Statement**\n",
    "- Is it clear what the goal of the project is?\n",
    "- What type of model will be developed?\n",
    "- How will success be evaluated?\n",
    "- Is the scope of the project appropriate?\n",
    "- Is it clear who cares about this or why this is important to investigate?\n",
    "- Does the student consider the audience and the primary and secondary stakeholders?\n",
    "\n",
    "**Data Collection**\n",
    "- Was enough data gathered to generate a significant result?\n",
    "- Was data collected that was useful and relevant to the project?\n",
    "- Was data collection and storage optimized through custom functions, pipelines, and/or automation?\n",
    "- Was thought given to the server receiving the requests such as considering number of requests per second?\n",
    "\n",
    "**Data Cleaning and EDA**\n",
    "- Are missing values imputed/handled appropriately?\n",
    "- Are distributions examined and described?\n",
    "- Are outliers identified and addressed?\n",
    "- Are appropriate summary statistics provided?\n",
    "- Are steps taken during data cleaning and EDA framed appropriately?\n",
    "- Does the student address whether or not they are likely to be able to answer their problem statement with the provided data given what they've discovered during EDA?\n",
    "\n",
    "**Preprocessing and Modeling**\n",
    "- Is text data successfully converted to a matrix representation?\n",
    "- Are methods such as stop words, stemming, and lemmatization explored?\n",
    "- Does the student properly split and/or sample the data for validation/training purposes?\n",
    "- Does the student test and evaluate a variety of models to identify a production algorithm (**AT MINIMUM:** Bayes and one other model), Mahdi suggests a logreg model?\n",
    "- Does the student defend their choice of production model relevant to the data at hand and the problem?\n",
    "- Does the student explain how the model works and evaluate its performance successes/downfalls?\n",
    "\n",
    "**Evaluation and Conceptual Understanding**\n",
    "- Does the student accurately identify and explain the baseline score?\n",
    "- Does the student select and use metrics relevant to the problem objective?\n",
    "- Does the student interpret the results of their model for purposes of inference?\n",
    "- Is domain knowledge demonstrated when interpreting results?\n",
    "- Does the student provide appropriate interpretation with regards to descriptive and inferential statistics?\n",
    "\n",
    "**Conclusion and Recommendations**\n",
    "- Does the student provide appropriate context to connect individual steps back to the overall project?\n",
    "- Is it clear how the final recommendations were reached?\n",
    "- Are the conclusions/recommendations clearly stated?\n",
    "- Does the conclusion answer the original problem statement?\n",
    "- Does the student address how findings of this research can be applied for the benefit of stakeholders?\n",
    "- Are future steps to move the project forward identified?\n",
    "\n",
    "\n",
    "### Organization and Professionalism\n",
    "\n",
    "**Project Organization**\n",
    "- Are modules imported correctly (using appropriate aliases)?\n",
    "- Are data imported/saved using relative paths?\n",
    "- Does the README provide a good executive summary of the project?\n",
    "- Is markdown formatting used appropriately to structure notebooks?\n",
    "- Are there an appropriate amount of comments to support the code?\n",
    "- Are files & directories organized correctly?\n",
    "- Are there unnecessary files included?\n",
    "- Do files and directories have well-structured, appropriate, consistent names?\n",
    "\n",
    "**Visualizations**\n",
    "- Are sufficient visualizations provided?\n",
    "- Do plots accurately demonstrate valid relationships?\n",
    "- Are plots labeled properly?\n",
    "- Are plots interpreted appropriately?\n",
    "- Are plots formatted and scaled appropriately for inclusion in a notebook-based technical report?\n",
    "\n",
    "**Python Syntax and Control Flow**\n",
    "- Is care taken to write human readable code?\n",
    "- Is the code syntactically correct (no runtime errors)?\n",
    "- Does the code generate desired results (logically correct)?\n",
    "- Does the code follows general best practices and style guidelines?\n",
    "- Are Pandas functions used appropriately?\n",
    "- Are `sklearn` and `NLTK` methods used appropriately?\n",
    "\n",
    "**Presentation**\n",
    "- Is the problem statement clearly presented?\n",
    "- Does a strong narrative run through the presentation building toward a final conclusion?\n",
    "- Are the conclusions/recommendations clearly stated?\n",
    "- Is the level of technicality appropriate for the intended audience?\n",
    "- Is the student substantially over or under time?\n",
    "- Does the student appropriately pace their presentation?\n",
    "- Does the student deliver their message with clarity and volume?\n",
    "- Are appropriate visualizations generated for the intended audience?\n",
    "- Are visualizations necessary and useful for supporting conclusions/explaining findings?\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Why we choose this project for you?\n",
    "This project covers three of the biggest concepts we cover in the class: Classification Modeling, Natural Language Processing and Data Wrangling/Acquisition.\n",
    "\n",
    "Part 1 of the project focuses on **Data wrangling/gathering/acquisition**. This is a very important skill as not all the data you will need will be in clean CSVs or a single table in SQL.  There is a good chance that wherever you land you will have to gather some data from some unstructured/semi-structured sources; when possible, requesting information from an API, but often scraping it because they don't have an API (or it's terribly documented).\n",
    "\n",
    "Part 2 of the project focuses on **Natural Language Processing** and converting standard text data (like Titles and Comments) into a format that allows us to analyze it and use it in modeling.\n",
    "\n",
    "Part 3 of the project focuses on **Classification Modeling**.  Given that project 2 was a regression focused problem, we needed to give you a classification focused problem to practice the various models, means of assessment and preprocessing associated with classification.   \n",
    "\n",
    "\n",
    "Notes: Even if I end up removing it from the project, list appropriate steps in markdown.  Always show baseline model!  Next model needs to be a classification model.  We need train score, test score, cross-val.  Model selection showcases scores of models, but we do not need cross-val in this section.\n",
    "\n",
    "Notes: Show confusion matrix & in a graph.  Mahdi was able to show misclassifiers, which is actually what I would like to find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am a comedy writer (True Story).  I've run out of my own original ideas, so in order to get a good idea to pitch to Mike Schur, I want to find common word choice/themes that fans of both The Good Place and Parks & Recreation are using.  While I want my KNN and Bayes models to have high accuracy, I want to look at what my models are incorrectly able to predict, and the overlap will help me generate an idea of what type of show I can write that Mike Schur will want to further develop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import time\n",
    "import requests\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import regex as re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahdi helped us build this code through his intro lesson\n",
    "def query_pushshift(subreddit, kind = 'submission', day_window = 365, n = 14):\n",
    "    SUBFIELDS = ['title', 'selftext', 'subreddit', 'created_utc',\n",
    "                 'author', 'num_comments', 'score', 'is_self', 'is_original_content',\n",
    "                'over_18','is_crosspostable']\n",
    "    \n",
    "    # establish base url and stem\n",
    "    BASE_URL = f\"https://api.pushshift.io/reddit/search/{kind}\" # also known as the \"API endpoint\" \n",
    "    stem = f\"{BASE_URL}?subreddit={subreddit}&size=500\" # always pulling max of 500\n",
    "    \n",
    "    # instantiate empty list for temp storage\n",
    "    posts = []\n",
    "    \n",
    "    # implement for loop with `time.sleep(2)`\n",
    "    for i in range(1, n + 1):\n",
    "        URL = \"{}&after={}d\".format(stem, day_window * i)\n",
    "        print(\"Querying from: \" + URL)\n",
    "        response = requests.get(URL)\n",
    "        assert response.status_code == 200\n",
    "        mine = response.json()['data']\n",
    "        df = pd.DataFrame.from_dict(mine)\n",
    "        posts.append(df)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # pd.concat storage list\n",
    "    full = pd.concat(posts, sort=False)\n",
    "    \n",
    "    # if submission\n",
    "    if kind == \"submission\":\n",
    "        # select desired columns\n",
    "        full = full[SUBFIELDS]\n",
    "        # drop duplicates\n",
    "        full.drop_duplicates(inplace = True)\n",
    "        # select `is_self` == True\n",
    "        full = full.loc[full['is_self'] == True]\n",
    "\n",
    "    # create `timestamp` column\n",
    "    full['timestamp'] = full[\"created_utc\"].map(dt.date.fromtimestamp)\n",
    "    \n",
    "    print(\"Query Complete!\")    \n",
    "    return full "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=TheGoodPlace&size=500&after=365d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=TheGoodPlace&size=500&after=730d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=TheGoodPlace&size=500&after=1095d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=TheGoodPlace&size=500&after=1460d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=TheGoodPlace&size=500&after=1825d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=TheGoodPlace&size=500&after=2190d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=TheGoodPlace&size=500&after=2555d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=TheGoodPlace&size=500&after=2920d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=TheGoodPlace&size=500&after=3285d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=TheGoodPlace&size=500&after=3650d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=TheGoodPlace&size=500&after=4015d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=TheGoodPlace&size=500&after=4380d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=TheGoodPlace&size=500&after=4745d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=TheGoodPlace&size=500&after=5110d\n",
      "Query Complete!\n"
     ]
    }
   ],
   "source": [
    "good_place_df = query_pushshift('TheGoodPlace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1026, 12)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_place_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=365d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=730d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=1095d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=1460d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=1825d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=2190d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=2555d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=2920d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=3285d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=3650d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=4015d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=4380d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=4745d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=5110d\n",
      "Query Complete!\n"
     ]
    }
   ],
   "source": [
    "parks_and_rec_df = query_pushshift('PandR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1117, 12)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parks_and_rec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([parks_and_rec_df, good_place_df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>over_18</th>\n",
       "      <th>is_crosspostable</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hulu vs Netflix</td>\n",
       "      <td>So many differences! I'm watching Season 2 Ep ...</td>\n",
       "      <td>PandR</td>\n",
       "      <td>1556148216</td>\n",
       "      <td>DevoidSauce</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMV: Onceb one has been faithfully all the way...</td>\n",
       "      <td></td>\n",
       "      <td>PandR</td>\n",
       "      <td>1556155364</td>\n",
       "      <td>DariusMDeV</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMV: Once one has been faithfully through the ...</td>\n",
       "      <td></td>\n",
       "      <td>PandR</td>\n",
       "      <td>1556155446</td>\n",
       "      <td>DariusMDeV</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Small Thing I Noticed With “Sister City”</td>\n",
       "      <td>At the end of the episode when that Venezuela...</td>\n",
       "      <td>PandR</td>\n",
       "      <td>1556159655</td>\n",
       "      <td>Hejwiowknnmz</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I just realized that in the episode Article Tw...</td>\n",
       "      <td></td>\n",
       "      <td>PandR</td>\n",
       "      <td>1556191863</td>\n",
       "      <td>UnoriginalName373</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-04-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                    Hulu vs Netflix   \n",
       "1  CMV: Onceb one has been faithfully all the way...   \n",
       "2  CMV: Once one has been faithfully through the ...   \n",
       "3           Small Thing I Noticed With “Sister City”   \n",
       "4  I just realized that in the episode Article Tw...   \n",
       "\n",
       "                                            selftext subreddit  created_utc  \\\n",
       "0  So many differences! I'm watching Season 2 Ep ...     PandR   1556148216   \n",
       "1                                                        PandR   1556155364   \n",
       "2                                                        PandR   1556155446   \n",
       "3   At the end of the episode when that Venezuela...     PandR   1556159655   \n",
       "4                                                        PandR   1556191863   \n",
       "\n",
       "              author  num_comments  score  is_self is_original_content  \\\n",
       "0        DevoidSauce             0      2     True               False   \n",
       "1         DariusMDeV             0      1     True               False   \n",
       "2         DariusMDeV             5      2     True               False   \n",
       "3       Hejwiowknnmz             2     21     True               False   \n",
       "4  UnoriginalName373             2      5     True               False   \n",
       "\n",
       "   over_18 is_crosspostable   timestamp  \n",
       "0    False             True  2019-04-24  \n",
       "1    False             True  2019-04-24  \n",
       "2    False             True  2019-04-24  \n",
       "3    False             True  2019-04-24  \n",
       "4    False             True  2019-04-25  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>over_18</th>\n",
       "      <th>is_crosspostable</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>Janet Cosplay</td>\n",
       "      <td>My wife is trying to put together a cosplay of...</td>\n",
       "      <td>TheGoodPlace</td>\n",
       "      <td>1491420552</td>\n",
       "      <td>arinlome</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>Knowing michael was evil didnt ruin his charac...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>TheGoodPlace</td>\n",
       "      <td>1491589139</td>\n",
       "      <td>ardyraindropsrd</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>[SPOILER] Janet Theory</td>\n",
       "      <td>Please do not read this if you haven't watched...</td>\n",
       "      <td>TheGoodPlace</td>\n",
       "      <td>1491858194</td>\n",
       "      <td>BrianFoxShow</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>Is Janet Allegorical? [spoiler]</td>\n",
       "      <td>Since my Janet is god theory didn't resonate -...</td>\n",
       "      <td>TheGoodPlace</td>\n",
       "      <td>1491921533</td>\n",
       "      <td>kdubstep</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>Having just finished the (amazing) first seaso...</td>\n",
       "      <td>That pizza is DEFINITELY gluten-free.</td>\n",
       "      <td>TheGoodPlace</td>\n",
       "      <td>1492246895</td>\n",
       "      <td>weblowinherseys</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "2138                                      Janet Cosplay   \n",
       "2139  Knowing michael was evil didnt ruin his charac...   \n",
       "2140                             [SPOILER] Janet Theory   \n",
       "2141                    Is Janet Allegorical? [spoiler]   \n",
       "2142  Having just finished the (amazing) first seaso...   \n",
       "\n",
       "                                               selftext     subreddit  \\\n",
       "2138  My wife is trying to put together a cosplay of...  TheGoodPlace   \n",
       "2139                                          [removed]  TheGoodPlace   \n",
       "2140  Please do not read this if you haven't watched...  TheGoodPlace   \n",
       "2141  Since my Janet is god theory didn't resonate -...  TheGoodPlace   \n",
       "2142              That pizza is DEFINITELY gluten-free.  TheGoodPlace   \n",
       "\n",
       "      created_utc           author  num_comments  score  is_self  \\\n",
       "2138   1491420552         arinlome             3     13     True   \n",
       "2139   1491589139  ardyraindropsrd             7     24     True   \n",
       "2140   1491858194     BrianFoxShow            10     42     True   \n",
       "2141   1491921533         kdubstep             5      3     True   \n",
       "2142   1492246895  weblowinherseys             4     40     True   \n",
       "\n",
       "     is_original_content  over_18 is_crosspostable   timestamp  \n",
       "2138                 NaN    False              NaN  2017-04-05  \n",
       "2139                 NaN     True              NaN  2017-04-07  \n",
       "2140                 NaN    False              NaN  2017-04-10  \n",
       "2141                 NaN    False              NaN  2017-04-11  \n",
       "2142                 NaN    False              NaN  2017-04-15  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checked head and tail to ensure the data properly went to one dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                     0\n",
       "selftext                  0\n",
       "subreddit                 0\n",
       "created_utc               0\n",
       "author                    0\n",
       "num_comments              0\n",
       "score                     0\n",
       "is_self                   0\n",
       "is_original_content    1509\n",
       "over_18                   0\n",
       "is_crosspostable       1174\n",
       "timestamp                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of nulls in original content, and crosspostable.  I suspect these are likely Boolean categories that can be dummied, so I'm going to look further into that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    634\n",
       "Name: is_original_content, dtype: int64"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_original_content'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to keep orinal content column, since there are no True values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['is_original_content'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title               object\n",
       "selftext            object\n",
       "subreddit           object\n",
       "created_utc          int64\n",
       "author              object\n",
       "num_comments         int64\n",
       "score                int64\n",
       "is_self               bool\n",
       "over_18               bool\n",
       "is_crosspostable    object\n",
       "timestamp           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.143000e+03</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.475388e+09</td>\n",
       "      <td>10.414372</td>\n",
       "      <td>25.695287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.876195e+07</td>\n",
       "      <td>33.966947</td>\n",
       "      <td>75.988653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.295516e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.434691e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.494897e+09</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.525468e+09</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.560892e+09</td>\n",
       "      <td>887.000000</td>\n",
       "      <td>1310.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        created_utc  num_comments        score\n",
       "count  2.143000e+03   2143.000000  2143.000000\n",
       "mean   1.475388e+09     10.414372    25.695287\n",
       "std    6.876195e+07     33.966947    75.988653\n",
       "min    1.295516e+09      0.000000     0.000000\n",
       "25%    1.434691e+09      2.000000     2.000000\n",
       "50%    1.494897e+09      5.000000     8.000000\n",
       "75%    1.525468e+09     11.000000    20.000000\n",
       "max    1.560892e+09    887.000000  1310.000000"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "        ...  \n",
       "2138    False\n",
       "2139    False\n",
       "2140    False\n",
       "2141    False\n",
       "2142    False\n",
       "Name: is_crosspostable, Length: 2143, dtype: object"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_crosspostable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I will dummy crosspostable out as True and \"not True\", I am going to assume null values are false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('False', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['over_18'] = df['over_18'].astype(str).replace({\n",
    "    'False' : '0',\n",
    "    'True' : '1'\n",
    "}).astype(int)\n",
    "df['is_self'] = df['is_self'].astype(str).replace({\n",
    "    'False' : '0',\n",
    "    'True' : '1'\n",
    "}).astype(int)\n",
    "df['is_crosspostable'] = df['is_crosspostable'].astype(str).replace({\n",
    "    'False' : '0',\n",
    "    'True' : '1'\n",
    "}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>over_18</th>\n",
       "      <th>is_crosspostable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.143000e+03</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.475388e+09</td>\n",
       "      <td>10.414372</td>\n",
       "      <td>25.695287</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.426972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.876195e+07</td>\n",
       "      <td>33.966947</td>\n",
       "      <td>75.988653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083389</td>\n",
       "      <td>0.494754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.295516e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.434691e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.494897e+09</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.525468e+09</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.560892e+09</td>\n",
       "      <td>887.000000</td>\n",
       "      <td>1310.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        created_utc  num_comments        score  is_self      over_18  \\\n",
       "count  2.143000e+03   2143.000000  2143.000000   2143.0  2143.000000   \n",
       "mean   1.475388e+09     10.414372    25.695287      1.0     0.007000   \n",
       "std    6.876195e+07     33.966947    75.988653      0.0     0.083389   \n",
       "min    1.295516e+09      0.000000     0.000000      1.0     0.000000   \n",
       "25%    1.434691e+09      2.000000     2.000000      1.0     0.000000   \n",
       "50%    1.494897e+09      5.000000     8.000000      1.0     0.000000   \n",
       "75%    1.525468e+09     11.000000    20.000000      1.0     0.000000   \n",
       "max    1.560892e+09    887.000000  1310.000000      1.0     1.000000   \n",
       "\n",
       "       is_crosspostable  \n",
       "count       2143.000000  \n",
       "mean           0.426972  \n",
       "std            0.494754  \n",
       "min            0.000000  \n",
       "25%            0.000000  \n",
       "50%            0.000000  \n",
       "75%            1.000000  \n",
       "max            1.000000  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All values of is_self are 1, so I will drop that.  over_18 is a very imbalanced class, with only .7% having a true value, so I will drop that column too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['is_self', 'over_18'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1228\n",
       "True      915\n",
       "Name: is_crosspostable, dtype: int64"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_crosspostable'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "Do CountVectorizer, sum all of the rows together, sort, take the top 10-15 (show distribution by subreddit), from this list, we can create a custom list of subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_title = cvec.fit_transform(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-317-77f5e8eea991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcvec_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_title\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 ) from orig\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_get_axes\u001b[0;34m(N, K, index, columns)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   5355\u001b[0m             \u001b[0mindex_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5357\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     )\n\u001b[1;32m    437\u001b[0m             \u001b[0;31m# other iterable of some kind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36masarray_tuplesafe\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__array__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "cvec_title = pd.DataFrame(cv_title.toarray(), columns = cvec.get_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'selftext', 'subreddit', 'created_utc', 'author',\n",
       "       'num_comments', 'score', 'is_crosspostable', 'timestamp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
